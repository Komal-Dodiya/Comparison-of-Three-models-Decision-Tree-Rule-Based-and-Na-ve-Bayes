{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Name : Komal Vasant Dodiya\n",
        "\n",
        "UID  : U01948955\n",
        "\n",
        "Homework 2 : Play Tennis\n"
      ],
      "metadata": {
        "id": "3OGXYu0D2-t2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Step : 1,2   - Load the dataset and Libraries"
      ],
      "metadata": {
        "id": "TOKUUhjHB6Q6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uT_YQ1Wx0kzF"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "#Load the dataset from drive\n",
        "file_path='/content/drive/MyDrive/Data Mining/Homework 2/play_tennis_dataset.csv'\n",
        "tennis=pd.read_csv(file_path)\n",
        "tennis.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tennis.info()"
      ],
      "metadata": {
        "id": "SLaYF5FN2vGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tennis.isnull().sum()"
      ],
      "metadata": {
        "id": "slMfOUHj2y_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tennis.shape"
      ],
      "metadata": {
        "id": "ySCpGWs_6-9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tennis.duplicated().sum()"
      ],
      "metadata": {
        "id": "o2Lpl98d3lZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Step:3 - Data Preprocessing"
      ],
      "metadata": {
        "id": "y2K13hDSB0be"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Processing :\n",
        "#Here, we are Dropping a \"Day\" column , because \"Day\" is just an identifier (ID column) ,\n",
        "# it does not contain predictive information about whether someone will ‚ÄúPlay‚Äù or not."
      ],
      "metadata": {
        "id": "ujb04tsl3si1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tennis.drop('Day', axis=1)"
      ],
      "metadata": {
        "id": "zLflnwWz6kac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.2\twhy to  Fill 'None' values (if any) with the mode of the column?\n",
        "In our dataset, some rows have None under columns like Outlook, Temperature, Humidity, or Wind. When we load this dataset into pandas, \"None\" is a string, not a real missing value. But to the model, it‚Äôs still an invalid category ‚Äî not a real weather condition.\n"
      ],
      "metadata": {
        "id": "emcCvHqN_vF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tennis=tennis.replace(\"None\",np.nan) #This tells pandas:\"Treat these cells as missing data (NaN).\"\n",
        "tennis.head()"
      ],
      "metadata": {
        "id": "zzB9aBeC_0DB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Why mode? Because: All your features are categorical, not numeric.\n",
        "#The mode represents the most common category (like \"Sunny\" for Outlook or \"Weak\" for Wind).\n",
        "\n",
        "tennis = tennis.fillna(tennis.mode().iloc[0])\n",
        "tennis.head()\n",
        "# You can see changes in D3 outlook , earlier it was NaN and now with mode it has became Overcast."
      ],
      "metadata": {
        "id": "AMqYbHyb_0AY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Encode Categorical Variables"
      ],
      "metadata": {
        "id": "E1PVYG95CRqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert all categorical columns to numeric using LabelEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le_tennis= LabelEncoder()\n",
        "for col in tennis.columns:\n",
        "    tennis[col] = le_tennis.fit_transform(tennis[col])\n",
        "tennis.head()"
      ],
      "metadata": {
        "id": "VeLPPToS_z8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features (X) and target (y),Here Outlook, Temperature, Humidity, Wind ,Weather conditions (inputs)\n",
        "#Play is considered as Whether to play or not (output)\n",
        "\n",
        "tennis_x=tennis.drop('Play',axis=1) # all columns except target\n",
        "tennis_y=tennis['Play'] # target column\n",
        "tennis_x.head()"
      ],
      "metadata": {
        "id": "0oIMK37DDSUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Step 5: Train-Test Split"
      ],
      "metadata": {
        "id": "Cn0P0LuvFcNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(tennis_x,tennis_y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "IZOQeCQD_z5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6: Decision Tree (Gini)"
      ],
      "metadata": {
        "id": "Wfw7xoHGGaEg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "clf_gini = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
        "clf_gini.fit(X_train, y_train)\n",
        "\n",
        "y_pred_gini = clf_gini.predict(X_test)\n",
        "acc_gini = metrics.accuracy_score(y_test, y_pred_gini)\n",
        "\n",
        "print(\"\\n Gini Decision Tree Accuracy:\", round(acc_gini, 3))"
      ],
      "metadata": {
        "id": "Q2jjs39F_z2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7: Decision Tree (Entropy)"
      ],
      "metadata": {
        "id": "kGlfAp9uKDX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf_entropy = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
        "clf_entropy.fit(X_train, y_train)\n",
        "\n",
        "y_pred_entropy = clf_entropy.predict(X_test)\n",
        "acc_entropy = metrics.accuracy_score(y_test, y_pred_entropy)\n",
        "\n",
        "print(\"\\n Entropy Decision Tree Accuracy:\", round(acc_entropy, 3))"
      ],
      "metadata": {
        "id": "fSm0wlGV_zwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 8: Feature Importance\n",
        "\n",
        "When you train a Decision Tree, it decides how to split your data based on which features (columns) give the biggest reduction in impurity ‚Äî i.e., the best information gain or lowest Gini.\n",
        "\n",
        "So, feature importance shows you how much each feature contributed to improving the model‚Äôs predictions."
      ],
      "metadata": {
        "id": "-UL2xmZjKVci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "importances = pd.Series(clf_entropy.feature_importances_, index=tennis_x.columns)\n",
        "print(\"\\n Feature Importances:\\n\", importances.sort_values(ascending=False))\n",
        "\n",
        "# Visualize feature importances\n",
        "importances.sort_values().plot(kind='barh', color='skyblue', figsize=(6,4))\n",
        "plt.title(\"Feature Importance (Entropy Tree)\")\n",
        "plt.xlabel(\"Importance\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R-3SMclZ_zlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This means:\n",
        "\n",
        "Temperature and Outlook was the most decisive feature.\n",
        "\n",
        "Humidity and Wind shows the least impact."
      ],
      "metadata": {
        "id": "ein82pHTMwMb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 9: Visualize Decision Trees"
      ],
      "metadata": {
        "id": "FicdM2IINx5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(18,8))\n",
        "plot_tree(clf_entropy,\n",
        "          feature_names=tennis_x.columns,\n",
        "          class_names=['No', 'Yes'],\n",
        "          filled=True,\n",
        "          rounded=True,\n",
        "          fontsize=10)\n",
        "plt.title(\"Decision Tree (Entropy)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "oWJtBcB7_ykh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(18,8))\n",
        "plot_tree(clf_gini,\n",
        "          feature_names=tennis_x.columns,\n",
        "          class_names=['No', 'Yes'],\n",
        "          filled=True,\n",
        "          rounded=True,\n",
        "          fontsize=10)\n",
        "plt.title(\"Decision Tree (Gini)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y3SeP4xQ64HP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üßæ Step 10: Model Evaluation"
      ],
      "metadata": {
        "id": "FG2UR77AObWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n Classification Report (Entropy):\")\n",
        "print(metrics.classification_report(y_test, y_pred_entropy))\n",
        "\n",
        "print(\"\\n Classification Report (Gini):\")\n",
        "print(metrics.classification_report(y_test, y_pred_gini))"
      ],
      "metadata": {
        "id": "-1T5ddFHOcoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step : 2 - Rule Based Model**"
      ],
      "metadata": {
        "id": "KBlYH1-KU5_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wittgenstein\n"
      ],
      "metadata": {
        "id": "T7Rk1bA1NqIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wittgenstein as lw\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "print(\"wittgenstein imported\")"
      ],
      "metadata": {
        "id": "HzXLZM8wNyHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ripper = lw.RIPPER()\n",
        "ripper.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "qSd5IsmmONJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f61c52b2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "#Load the dataset from drive\n",
        "file_path='/content/drive/MyDrive/Data Mining/Homework 2/play_tennis_dataset.csv'\n",
        "tennis=pd.read_csv(file_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d8a96d8"
      },
      "source": [
        "tennis=tennis.replace(\"None\",np.nan) #This tells pandas:\"Treat these cells as missing data (NaN).\"\n",
        "tennis = tennis.fillna(tennis.mode().iloc[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b67ea95"
      },
      "source": [
        "# Convert all categorical columns to numeric using LabelEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le_tennis= LabelEncoder()\n",
        "for col in tennis.columns:\n",
        "    tennis[col] = le_tennis.fit_transform(tennis[col])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "265de7f8"
      },
      "source": [
        "# Separate features (X) and target (y),Here Outlook, Temperature, Humidity, Wind ,Weather conditions (inputs)\n",
        "#Play is considered as Whether to play or not (output)\n",
        "\n",
        "tennis_x=tennis.drop('Play',axis=1) # all columns except target\n",
        "tennis_y=tennis['Play'] # target column"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ce59dd3"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(tennis_x,tennis_y, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cf0d86c"
      },
      "source": [
        "ripper = lw.RIPPER()\n",
        "ripper.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0074342"
      },
      "source": [
        "# Separate features (X) and target (y),Here Outlook, Temperature, Humidity, Wind ,Weather conditions (inputs)\n",
        "#Play is considered as Whether to play or not (output)\n",
        "\n",
        "tennis_x=tennis.drop('Play',axis=1) # all columns except target\n",
        "tennis_y=tennis['Play'] # target column\n",
        "tennis_x.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8f7c644"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(tennis_x,tennis_y, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12f79372"
      },
      "source": [
        "ripper = lw.RIPPER()\n",
        "ripper.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1dbd0b6"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(tennis_x,tennis_y, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d00b30a"
      },
      "source": [
        "ripper = lw.RIPPER()\n",
        "ripper.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the Performance\n",
        "y_pred = ripper.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "jdAz7n2dRqtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Generated RIPPER Rules:\\n\")\n",
        "print(ripper.ruleset_)\n"
      ],
      "metadata": {
        "id": "2Sx0dYgVRyK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "models = ['Decision Tree', 'RIPPER Model']\n",
        "accuracies = [acc_entropy, accuracy_score(y_test, y_pred)]\n",
        "\n",
        "plt.bar(models, accuracies)\n",
        "plt.title('Model Accuracy Comparison')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NzSxnIeKY9OO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summarize findings from Decision Tree and RIPPER models\n",
        "Based on your analysis:\n",
        "\n",
        "Decision Tree:\n",
        "\n",
        "Both the Gini and Entropy criteria resulted in the same accuracy of approximately 78.6%.\n",
        "The feature importance analysis showed that 'Temperature' and 'Outlook' were the most decisive features for the Decision Tree, while 'Humidity' and 'Wind' had the least impact.\n",
        "The visualized tree provides a clear, step-by-step decision process based on the features.\n",
        "RIPPER Model:\n",
        "\n",
        "The RIPPER model achieved a slightly higher accuracy of approximately 79.9%.\n",
        "The model provides a set of \"if-then\" rules that explain the classification. These rules can be more interpretable than a complex decision tree, although the generated rules in this case appear quite detailed due to the nature of the data and encoding.\n",
        "Comparison:\n",
        "\n",
        "Both models performed similarly in terms of overall accuracy on the test set, with the RIPPER model showing a slight edge.\n",
        "Decision Trees offer a visual representation of the decision process and feature importance.\n",
        "RIPPER provides a set of explicit rules, which can be valuable for understanding the conditions that lead to a particular classification.\n",
        "In summary, both models provide reasonable performance for this dataset. The choice between them might depend on whether interpretability through a tree structure or a set of rules is preferred."
      ],
      "metadata": {
        "id": "KFTc48nmZl_v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step - 3 : Naive Bayse Model"
      ],
      "metadata": {
        "id": "ZLlV0_LXhsbJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import cross_val_score, cross_validate, StratifiedKFold\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "VXLGNfomZnhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use GaussianNB (continuous features) or MultinomialNB (categorical count features)\n",
        "model = GaussianNB()\n",
        "\n",
        "# ---- 10-Fold Cross-Validation ----\n",
        "scoring = {\n",
        "    'accuracy': make_scorer(accuracy_score),\n",
        "    'precision': make_scorer(precision_score),\n",
        "    'recall': make_scorer(recall_score),\n",
        "    'f1': make_scorer(f1_score)\n",
        "}\n",
        "\n",
        "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "results = cross_validate(model, tennis_x, tennis_y, cv=cv, scoring=scoring)\n",
        "\n",
        "# ---- Display Results ----\n",
        "print(\"Na√Øve Bayes Model (10-Fold CV Results):\")\n",
        "print(f\"Accuracy: {results['test_accuracy'].mean():.3f}\")\n",
        "print(f\"Precision: {results['test_precision'].mean():.3f}\")\n",
        "print(f\"Recall: {results['test_recall'].mean():.3f}\")\n",
        "print(f\"F1-score: {results['test_f1'].mean():.3f}\")"
      ],
      "metadata": {
        "id": "FsLqBC4OjL9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Display comparison table of Decision Tree, Rule Based Model and Naive Bayes\n",
        "plt.figure\n",
        "models = ['Decision Tree', 'Rule Based Model', 'Na√Øve Bayes']\n",
        "accuracies = [acc_entropy, accuracy_score(y_test, y_pred), results['test_accuracy'].mean()]\n",
        "plt.bar(models, accuracies)\n",
        "plt.title('Model Accuracy Comparison')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7vGntp3tkwPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Evaluation and ROC Analysis"
      ],
      "metadata": {
        "id": "dexJajqklfbu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Evaluation and ROC Analysis\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, roc_curve, roc_auc_score,\n",
        "    precision_score, recall_score, f1_score, classification_report\n",
        ")\n",
        "\n",
        "# Holdout Evaluation for Decision Tree (Entropy)\n",
        "y_pred_dt_holdout = clf_entropy.predict(X_test)\n",
        "print(\"Classification Report (Decision Tree - Holdout):\")\n",
        "print(classification_report(y_test, y_pred_dt_holdout))\n",
        "\n",
        "# Holdout Evaluation for Naive Bayes\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "model_nb_holdout = GaussianNB()\n",
        "model_nb_holdout.fit(X_train, y_train)\n",
        "y_pred_nb_holdout = model_nb_holdout.predict(X_test)\n",
        "print(\"\\nClassification Report (Naive Bayes - Holdout):\")\n",
        "print(classification_report(y_test, y_pred_nb_holdout))"
      ],
      "metadata": {
        "id": "pcMEcGhuldHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c8e450e"
      },
      "source": [
        "# Task\n",
        "Perform 10-fold cross-validation and bootstrapping on the Decision Tree, RIPPER, and Naive Bayes models, then summarize and compare the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da3e4f79"
      },
      "source": [
        "## Perform 10-fold cross-validation\n",
        "\n",
        "### Subtask:\n",
        "Apply 10-Fold Cross-Validation to the models (Decision Tree, RIPPER, and Naive Bayes) to get a more robust estimate of their performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2fe40be"
      },
      "source": [
        "**Reasoning**:\n",
        "Apply 10-fold cross-validation to the Decision Tree and RIPPER models and print their mean performance metrics.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "561b933f"
      },
      "source": [
        "dt_cv_results = cross_validate(clf_entropy, tennis_x, tennis_y, cv=cv, scoring=scoring)\n",
        "ripper_cv_results = cross_validate(ripper, tennis_x, tennis_y, cv=cv, scoring=scoring)\n",
        "\n",
        "print(\"Decision Tree (Entropy) 10-Fold CV Results:\")\n",
        "print(f\"Accuracy: {dt_cv_results['test_accuracy'].mean():.3f}\")\n",
        "print(f\"Precision: {dt_cv_results['test_precision'].mean():.3f}\")\n",
        "print(f\"Recall: {dt_cv_results['test_recall'].mean():.3f}\")\n",
        "print(f\"F1-score: {dt_cv_results['test_f1'].mean():.3f}\")\n",
        "\n",
        "print(\"\\nRIPPER Model 10-Fold CV Results:\")\n",
        "print(f\"Accuracy: {ripper_cv_results['test_accuracy'].mean():.3f}\")\n",
        "print(f\"Precision: {ripper_cv_results['test_precision'].mean():.3f}\")\n",
        "print(f\"Recall: {ripper_cv_results['test_recall'].mean():.3f}\")\n",
        "print(f\"F1-score: {ripper_cv_results['test_f1'].mean():.3f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c24c7e4"
      },
      "source": [
        "## Perform bootstrapping\n",
        "\n",
        "### Subtask:\n",
        "Apply bootstrapping to the models to assess the variability of their performance metrics.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf36d4f3"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement bootstrapping to evaluate the models and calculate the mean and standard deviation of the metrics.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "200c62d6"
      },
      "source": [
        "n_bootstrap_samples = 20\n",
        "\n",
        "dt_acc_bootstrap = []\n",
        "dt_prec_bootstrap = []\n",
        "dt_rec_bootstrap = []\n",
        "dt_f1_bootstrap = []\n",
        "\n",
        "ripper_acc_bootstrap = []\n",
        "ripper_prec_bootstrap = []\n",
        "ripper_rec_bootstrap = []\n",
        "ripper_f1_bootstrap = []\n",
        "\n",
        "nb_acc_bootstrap = []\n",
        "nb_prec_bootstrap = []\n",
        "nb_rec_bootstrap = []\n",
        "nb_f1_bootstrap = []\n",
        "\n",
        "for _ in range(n_bootstrap_samples):\n",
        "    # Create bootstrap sample\n",
        "    bootstrap_indices = np.random.choice(len(X_train), size=len(X_train), replace=True)\n",
        "    X_train_bootstrap = X_train.iloc[bootstrap_indices]\n",
        "    y_train_bootstrap = y_train.iloc[bootstrap_indices]\n",
        "\n",
        "    # Train and evaluate Decision Tree\n",
        "    clf_entropy.fit(X_train_bootstrap, y_train_bootstrap)\n",
        "    y_pred_dt = clf_entropy.predict(X_test)\n",
        "    dt_acc_bootstrap.append(accuracy_score(y_test, y_pred_dt))\n",
        "    dt_prec_bootstrap.append(precision_score(y_test, y_pred_dt))\n",
        "    dt_rec_bootstrap.append(recall_score(y_test, y_pred_dt))\n",
        "    dt_f1_bootstrap.append(f1_score(y_test, y_pred_dt))\n",
        "\n",
        "    # Train and evaluate RIPPER\n",
        "    ripper.fit(X_train_bootstrap, y_train_bootstrap)\n",
        "    y_pred_ripper = ripper.predict(X_test)\n",
        "    ripper_acc_bootstrap.append(accuracy_score(y_test, y_pred_ripper))\n",
        "    ripper_prec_bootstrap.append(precision_score(y_test, y_pred_ripper))\n",
        "    ripper_rec_bootstrap.append(recall_score(y_test, y_pred_ripper))\n",
        "    ripper_f1_bootstrap.append(f1_score(y_test, y_pred_ripper))\n",
        "\n",
        "    # Train and evaluate Naive Bayes\n",
        "    model_nb_holdout.fit(X_train_bootstrap, y_train_bootstrap)\n",
        "    y_pred_nb = model_nb_holdout.predict(X_test)\n",
        "    nb_acc_bootstrap.append(accuracy_score(y_test, y_pred_nb))\n",
        "    nb_prec_bootstrap.append(precision_score(y_test, y_pred_nb))\n",
        "    nb_rec_bootstrap.append(recall_score(y_test, y_pred_nb))\n",
        "    nb_f1_bootstrap.append(f1_score(y_test, y_pred_nb))\n",
        "\n",
        "# Calculate and print bootstrap results\n",
        "print(\"Bootstrap Results (Mean ¬± Std Dev):\")\n",
        "\n",
        "print(\"\\nDecision Tree (Entropy):\")\n",
        "print(f\"Accuracy: {np.mean(dt_acc_bootstrap):.3f} ¬± {np.std(dt_acc_bootstrap):.3f}\")\n",
        "print(f\"Precision: {np.mean(dt_prec_bootstrap):.3f} ¬± {np.std(dt_prec_bootstrap):.3f}\")\n",
        "print(f\"Recall: {np.mean(dt_rec_bootstrap):.3f} ¬± {np.std(dt_rec_bootstrap):.3f}\")\n",
        "print(f\"F1-score: {np.mean(dt_f1_bootstrap):.3f} ¬± {np.std(dt_f1_bootstrap):.3f}\")\n",
        "\n",
        "print(\"\\nRIPPER Model:\")\n",
        "print(f\"Accuracy: {np.mean(ripper_acc_bootstrap):.3f} ¬± {np.std(ripper_acc_bootstrap):.3f}\")\n",
        "print(f\"Precision: {np.mean(ripper_prec_bootstrap):.3f} ¬± {np.std(ripper_prec_bootstrap):.3f}\")\n",
        "print(f\"Recall: {np.mean(ripper_rec_bootstrap):.3f} ¬± {np.std(ripper_rec_bootstrap):.3f}\")\n",
        "print(f\"F1-score: {np.mean(ripper_f1_bootstrap):.3f} ¬± {np.std(ripper_f1_bootstrap):.3f}\")\n",
        "\n",
        "print(\"\\nNaive Bayes Model:\")\n",
        "print(f\"Accuracy: {np.mean(nb_acc_bootstrap):.3f} ¬± {np.std(nb_acc_bootstrap):.3f}\")\n",
        "print(f\"Precision: {np.mean(nb_prec_bootstrap):.3f} ¬± {np.std(nb_prec_bootstrap):.3f}\")\n",
        "print(f\"Recall: {np.mean(nb_rec_bootstrap):.3f} ¬± {np.std(nb_rec_bootstrap):.3f}\")\n",
        "print(f\"F1-score: {np.mean(nb_f1_bootstrap):.3f} ¬± {np.std(nb_f1_bootstrap):.3f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ROC curve\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Compute ROC AUC on holdout test set\n",
        "dt_probs = clf_entropy.predict_proba(X_test)[:, 1]\n",
        "nb_probs = model_nb_holdout.predict_proba(X_test)[:, 1]\n",
        "\n",
        "dt_auc = roc_auc_score(y_test, dt_probs)\n",
        "nb_auc = roc_auc_score(y_test, nb_probs)\n",
        "\n",
        "dt_fpr, dt_tpr, _ = roc_curve(y_test, dt_probs)\n",
        "nb_fpr, nb_tpr, _ = roc_curve(y_test, nb_probs)\n",
        "\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.plot(dt_fpr, dt_tpr, label=f\"Decision Tree (AUC = {dt_auc:.2f})\")\n",
        "plt.plot(nb_fpr, nb_tpr, label=f\"Na√Øve Bayes (AUC = {nb_auc:.2f})\")\n",
        "plt.plot([0,1], [0,1], 'k--')  # diagonal line\n",
        "plt.title(\"ROC Curve Comparison\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "P0fsGmk4qPKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Holdout accuracy ‚Äî single train/test split.\n",
        "\n",
        "10-Fold Cross-Validation ‚Äî averaged accuracy and standard deviation.\n",
        "\n",
        "Bootstrap accuracy ‚Äî average performance over resampled datasets.\n",
        "\n",
        "ROC Curve plot ‚Äî visual comparison of the classifiers‚Äô ability to distinguish classes."
      ],
      "metadata": {
        "id": "T9ClkrPfrb0-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_iF99Syfrd-j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}